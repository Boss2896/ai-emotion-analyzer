<!DOCTYPE html>
<html lang="az">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Universal Analyzer</title>
    <style>
        body { font-family: 'Segoe UI', sans-serif; background: #0f0f0f; color: white; text-align: center; padding: 20px; }
        .container { max-width: 700px; margin: auto; background: #1a1a1a; padding: 30px; border-radius: 20px; box-shadow: 0 10px 30px rgba(0,0,0,0.5); border: 1px solid #333; }
        h1 { color: #00ff96; margin-bottom: 10px; }
        textarea { width: 100%; height: 120px; padding: 15px; border-radius: 10px; border: 1px solid #444; background: #252525; color: white; margin-bottom: 15px; box-sizing: border-box; font-size: 16px; }
        .btn-group { display: flex; gap: 10px; justify-content: center; flex-wrap: wrap; margin-bottom: 25px; }
        button { border: none; padding: 12px 25px; border-radius: 8px; cursor: pointer; font-weight: bold; transition: 0.3s; font-size: 14px; }
        .btn-analyze { background: #00ff96; color: black; }
        .btn-analyze:hover { background: #00cc78; transform: translateY(-2px); }
        .btn-mic { background: #ff4b2b; color: white; }
        .btn-mic.recording { animation: pulse 1.5s infinite; background: #ff0000; }
        @keyframes pulse { 0% { box-shadow: 0 0 0 0 rgba(255, 75, 43, 0.7); } 70% { box-shadow: 0 0 0 15px rgba(255, 75, 43, 0); } 100% { box-shadow: 0 0 0 0 rgba(255, 75, 43, 0); } }
        #result, #imageResult { margin-top: 20px; padding: 20px; border-radius: 12px; background: #252525; text-align: left; border-left: 5px solid #00ff96; display: none; }
        .image-section { border-top: 1px solid #333; margin-top: 30px; padding-top: 20px; }
        input[type="file"] { margin: 15px 0; color: #888; }
        img { max-width: 100%; border-radius: 10px; margin-top: 10px; border: 2px solid #444; }
        .status-text { font-style: italic; color: #00ff96; }
    </style>
</head>
<body>

<div class="container">
    <h1>ü§ñ AI Universal Analyzer</h1>
    <p>S…ôs, M…ôtn v…ô ≈û…ôkil vasit…ôsil…ô s√ºni intellekt analizi</p>
    
    <textarea id="userInput" placeholder="Bura bir ≈üeyl…ôr yazƒ±n v…ô ya mikrofonu istifad…ô edin..."></textarea>
    
    <div class="btn-group">
        <button id="micBtn" class="btn-mic" onclick="toggleMic()">üé§ Mikrofonu A√ß</button>
        <button class="btn-analyze" onclick="analyzeText()">Duyƒüunu Analiz Et</button>
    </div>

    <div id="result">
        <strong>Analiz N…ôtic…ôsi:</strong>
        <p id="emotionDisplay" style="font-size: 1.2em;"></p>
        <p id="transcriptOutput" style="color: #888; font-size: 0.9em;"></p>
    </div>

    <div class="image-section">
        <h3>üñºÔ∏è ≈û…ôkil Redakt…ôsi</h3>
        <input type="file" id="imageInput" accept="image/*">
        <div class="btn-group">
            <button class="btn-analyze" onclick="processImage('grayscale')">Aƒü-Qara</button>
            <button class="btn-analyze" onclick="processImage('blur')">Bulanƒ±q (Blur)</button>
        </div>
        
        <div id="imageResult">
            <p class="status-text">‚úÖ Emal olundu:</p>
            <img id="outputImage" src="" alt="N…ôtic…ô">
        </div>
    </div>
</div>

<script>
    // --- 1. S∆èS V∆è M∆èTN ANALƒ∞Zƒ∞ ---
    let recognition;
    let isRecording = false;

    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        recognition = new SpeechRecognition();
        recognition.lang = 'az-AZ';
        recognition.onresult = (event) => {
            const transcript = event.results[0][0].transcript;
            document.getElementById('userInput').value = transcript;
            stopRecording();
            analyzeText();
        };
    }

    function toggleMic() {
        if (!recognition) return alert("S…ôs tanƒ±ma d…ôst…ôkl…ônmir.");
        isRecording ? stopRecording() : startRecording();
    }

    function startRecording() {
        isRecording = true;
        recognition.start();
        document.getElementById('micBtn').innerText = "üõë Dayandƒ±r...";
        document.getElementById('micBtn').classList.add('recording');
    }

    function stopRecording() {
        isRecording = false;
        recognition.stop();
        document.getElementById('micBtn').innerText = "üé§ Mikrofonu A√ß";
        document.getElementById('micBtn').classList.remove('recording');
    }

    async function analyzeText() {
        const text = document.getElementById('userInput').value;
        if(!text) return;

        try {
            const response = await fetch('/api/text-emotion', {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ text })
            });
            const data = await response.json();

            if(data.success) {
                const emo = data.emotion.emotion;
                const emoji = emo === 'positive' ? 'üòä M√ºsb…ôt' : emo === 'negative' ? 'üòî M…ônfi' : 'üòê Neytral';
                
                document.getElementById('result').style.display = 'block';
                document.getElementById('emotionDisplay').innerHTML = `Emosiya: <strong>${emoji}</strong>`;
                document.getElementById('transcriptOutput').innerText = "M…ôtn: " + text;
                
                speak(`Analiz tamamlandƒ±. Bu m…ôtnd…ô ${emo === 'positive' ? 'm√ºsb…ôt' : emo === 'negative' ? 'm…ônfi' : 'neytral'} ton hiss etdim.`);
            }
        } catch (e) { alert("X…ôta!"); }
    }

    // --- 2. S∆èSLƒ∞ CAVAB (TTS) ---
    function speak(text) {
        window.speechSynthesis.cancel();
        const msg = new SpeechSynthesisUtterance(text);
        msg.lang = 'tr-TR'; 
        window.speechSynthesis.speak(msg);
    }

    // --- 3. ≈û∆èKƒ∞L EMALI ---
    async function processImage(type) {
        const file = document.getElementById('imageInput').files[0];
        if (!file) return alert("≈û…ôkil se√ßin!");

        const formData = new FormData();
        formData.append('image', file);
        formData.append('operations', JSON.stringify(type === 'grayscale' ? { grayscale: true } : { blur: 5 }));

        try {
            const response = await fetch('/api/image-edit', { method: 'POST', body: formData });
            const data = await response.json();
            if (data.success) {
                document.getElementById('imageResult').style.display = 'block';
                document.getElementById('outputImage').src = '/' + data.editedPath;
                speak("≈û…ôkil redakt…ô edildi.");
            }
        } catch (e) { alert("≈û…ôkil x…ôtasƒ±!"); }
    }
</script>

</body>
  </html>

